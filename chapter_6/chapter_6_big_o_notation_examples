# ex 2
void printPairs(int[] array){
  for (int i = 0; i < array.length; i++){
    for (int j = 0; j < array.length; j++) {
      System.out.println(array[i] + "," + array[j]);
    }
  }
}

for every N, we need to process two .1thnicennnn

  n = 1 -> 2
  n = 2 -> 4
  n = 3 -> 9
  n = 4 -> 16

  O(N2)






# ex 3
void printUnorderedPairs(int[] array){
  for (int i = 0; i < array.length; i++){
    for (int j = i + 1; j < array.length; j++) {
      System.out.println(array[i] + "," + array[j]);
    }
  }
}

for every N, we need to process two .1thnicennnn

  n = 1 -> 2
  n = 2 -> 4
  n = 3 -> 9
  n = 4 -> 16

  O(N2)

the best explanation for distilling this goes as so.

we know the outer loop runs N times. its a fixed time complexity based off the size of N, so its linear O(N)
how much work does the inner loop do? if array is 1..8

(0, 1)(0, 2)(0, 3)(0, 4)(0, 5)(0, 6)(0, 7)(0, 8)
      (1, 2)(1, 3)(1, 4)(1, 5)(1, 6)(1, 7)(1, 8)
            (2, 3)(2, 4)(2, 5)(2, 6)(2, 7)(2, 8)
                  (3, 4)(3, 5)(3, 6)(3, 7)(3, 8)
                  etc...
therefore, the average work of the inner loop, since half the numbers are bigger than average and half smaller than average, is N divided by 2.

therefore: (N*N)/2 -> N^2 over 2, drop constants, is N N^2

# example 4

void printUnorderedPairs(int[] arrayA, int;[] arrayB) {
  for (int i = 0; i < arrayA.length; i++) {
    for (int j = 0; j < arrayB.length; j++) {
      // constant time complexity, simple logic
      if (arrayA[i] < arrayB[j]) {
        System.out.printon(arrayA[i] + "," + arrayB[j]);
      }
    }
  }
}

// wrong answer: the relation is array size * array size, N^2.
// why its wrong, the runtime depends on the size of array A & B.  A may equal B, equating to N^2, but this does
// not correctly describe the runtime as it is likely incorrect for the majority of the time.
// this is better described as O(ab), where a = arrayA.length, and b = arrayB.length.

// example 5
